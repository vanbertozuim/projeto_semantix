{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Final de Spark - Nível Básico\n",
    "Campanha Nacional de Vacinação contra Covid-19: Dados e Referência das Visualizações\n",
    "\n",
    "Aluno: Vanberto Zuim\n",
    "\n",
    "Descrição das fórmulas que serão utilizadas para obter os dados do painel\n",
    "Coeficiente de Incidência: Número de casos confirmados de COVID-19, por 100 mil habitantes, na população residente em determinado espaço geográfico, no período considerado.\n",
    "\n",
    "Coeficiente de Mortalidade: Número de óbitos por doenças COVID-19, por 100 mil habitantes, na população residente em determinado espaço geográfico, no período considerado.\n",
    "\n",
    "Taxa de Letalidade: Número de óbitos confirmados de COVID-19 em relação ao total de casos confirmados, na população residente em determinado espaço geográfico, no período considerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos pacotes necessários\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Enviar os dados para o hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa realizada no terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   3 root supergroup   62492959 2022-08-05 03:00 /user/vanberto/covid/HIST_PAINEL_COVIDBR_2020_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   76520681 2022-08-05 03:00 /user/vanberto/covid/HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   91120916 2022-08-05 03:00 /user/vanberto/covid/HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup    3046774 2022-08-05 03:00 /user/vanberto/covid/HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Listagem dos arquivos presentes no hdfs\n",
    "\n",
    "!hdfs dfs -ls -R /user/vanberto/covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: timestamp (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: integer (nullable = true)\n",
      " |-- casosAcumulado: decimal(10,0) (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: integer (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- Recuperadosnovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interior/metropolitana: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados e visualizaçõs do schema\n",
    "\n",
    "df = spark.read.csv(\"/user/vanberto/covid/*.csv\", sep =';', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste do tipo dos dados - Informações são diárias, não necessita do campo hora\n",
    "\n",
    "df = df.withColumn('data', f.from_unixtime(f.unix_timestamp(df.data), \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"obitosAcumulado\", col(\"obitosAcumulado\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+--------------+\n",
      "|data      |regiao|casosNovos|casosAcumulado|\n",
      "+----------+------+----------+--------------+\n",
      "|2021-01-01|Brasil|24605     |7700578       |\n",
      "|2021-01-02|Brasil|15827     |7716405       |\n",
      "|2021-01-03|Brasil|17341     |7733746       |\n",
      "|2021-01-04|Brasil|20006     |7753752       |\n",
      "|2021-01-05|Brasil|56648     |7810400       |\n",
      "|2021-01-06|Brasil|63430     |7873830       |\n",
      "|2021-01-07|Brasil|87843     |7961673       |\n",
      "|2021-01-08|Brasil|52035     |8013708       |\n",
      "|2021-01-09|Brasil|62290     |8075998       |\n",
      "|2021-01-10|Brasil|29792     |8105790       |\n",
      "+----------+------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualização de quatro colunas da tabela dados\n",
    "\n",
    "df.select('data','regiao','casosNovos','casosAcumulado').show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Otimizar todos os dados do hdfs para uma tabela Hive particionada por município"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os dados em tabela Hive particionada por município\n",
    "\n",
    "df.write.mode('overwrite').partitionBy('municipio').saveAsTable('vanberto.projeto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-05 13:14 /user/hive/warehouse/vanberto.db/projeto\r\n"
     ]
    }
   ],
   "source": [
    "# Identificação da tabela Hive criada\n",
    "\n",
    "!hdfs dfs -ls /user/hive/warehouse/vanberto.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|partition                    |\n",
      "+-----------------------------+\n",
      "|municipio=Abadia de Goiás    |\n",
      "|municipio=Abadia dos Dourados|\n",
      "|municipio=Abadiânia          |\n",
      "|municipio=Abaetetuba         |\n",
      "|municipio=Abaeté             |\n",
      "|municipio=Abaiara            |\n",
      "|municipio=Abaré              |\n",
      "|municipio=Abatiá             |\n",
      "|municipio=Abaíra             |\n",
      "|municipio=Abdon Batista      |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualização das partições criadas - apenas as 10 primeiras em ordem alfabética\n",
    "\n",
    "spark.sql('show partitions vanberto.projeto').show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Criar as 3 visualizações pelo Spark com os dados enviados para o HDFS\n",
    "PAINEL 1 - Casos Recuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados estão atualizados até o dia 06/07/2021\n",
    "\n",
    "data = \"2021-07-06\"\n",
    "br = df.where((df.regiao == 'Brasil') & (df.data == data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-----------------+\n",
      "|Região|Casos_Recuperados|Em_Acompanhamento|\n",
      "+------+-----------------+-----------------+\n",
      "|Brasil|         17262646|          1065477|\n",
      "+------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Número de casos recuperados e em acompanhamento - nível nacional (06/07/2021)\n",
    "\n",
    "recuperados_br = br.select(br['regiao'].alias('Região'),\\\n",
    "                           br['Recuperadosnovos'].alias('Casos_Recuperados'),\\\n",
    "                           br['emAcompanhamentoNovos'].alias('Em_Acompanhamento'))\n",
    "recuperados_br.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAINEL 2 - Casos Confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-----------+----------+\n",
      "|Região|Casos_Acumulados|Casos_Novos|Incidência|\n",
      "+------+----------------+-----------+----------+\n",
      "|Brasil|        18855015|      62504|    8972.3|\n",
      "+------+----------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Número de casos acumulados, casos novos e incidência - nível nacional (06/07/2021)\n",
    "\n",
    "casos_br = br.select(br['regiao'].alias('Região'),\\\n",
    "                     br['casosAcumulado'].alias('Casos_Acumulados'),\\\n",
    "                     br['casosNovos'].alias('Casos_Novos'),\\\n",
    "                    (f.round(br['casosAcumulado']/br['populacaoTCU2019']*100000,1)).alias('Incidência'))\n",
    "casos_br.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAINEL 3 - Óbitos Confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+------------+----------+-----------+\n",
      "|Região|Óbitos_Acumulados|Óbitos_Novos|Letalidade|Mortalidade|\n",
      "+------+-----------------+------------+----------+-----------+\n",
      "|Brasil|           526892|        1780|       2.8|      250.7|\n",
      "+------+-----------------+------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Número de óbitos acumulados, óbitos novos, letalidade e mortalidade - nível nacional (06/07/2021)\n",
    "\n",
    "obitos_br = br.select(br['regiao'].alias('Região'),\\\n",
    "                      br['obitosAcumulado'].alias('Óbitos_Acumulados'),\\\n",
    "                      br['obitosNovos'].alias('Óbitos_Novos'),\\\n",
    "                     (f.round(br['obitosAcumulado']/br['casosAcumulado']*100,1)).alias('Letalidade'),\\\n",
    "                     (f.round(br['obitosAcumulado']/br['populacaoTCU2019']*100000,1)).alias('Mortalidade'))\n",
    "obitos_br.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Salvar a primeira visualização como tabela Hive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação e identificação da tabela Hive com os dados do primeiro painel\n",
    "# Por padrão o método save() salva no formato parquet e compressão snappy\n",
    "\n",
    "recuperados_br.write.mode('overwrite').saveAsTable('recuperados_br_covid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-08-05 13:38 /user/hive/warehouse/recuperados_br_covid/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        483 2022-08-05 13:38 /user/hive/warehouse/recuperados_br_covid/part-00000-63f1ad7e-12e1-4ddf-8b56-15d95479a295-c000.snappy.parquet\r\n",
      "-rw-r--r--   2 root supergroup        917 2022-08-05 13:38 /user/hive/warehouse/recuperados_br_covid/part-00002-63f1ad7e-12e1-4ddf-8b56-15d95479a295-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/recuperados_br_covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Salvar a terceira visualização em um tópico no Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um tópico no kafka com os dados do terceiro painel\n",
    "# As colunas serão transformadas em um json para enviar todos os dados em um unico tópico\n",
    "\n",
    "obitos_br\\\n",
    "    .selectExpr(\"to_json(struct(*)) AS value\")\\\n",
    "    .write\\\n",
    "    .format('kafka')\\\n",
    "    .option('kafka.bootstrap.servers', 'kafka:9092')\\\n",
    "    .option('topic', 'obitos_brasil')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                  |\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}|\n",
      "|{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}|\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para conferir a criação do tópico, realizamos a leitura dele\n",
    "\n",
    "obitos_topic = spark.read\\\n",
    "    .format('kafka')\\\n",
    "    .option('kafka.bootstrap.servers', 'kafka:9092')\\\n",
    "    .option('subscribe','obitos_brasil') \\\n",
    "    .load()\n",
    "\n",
    "topic_string = obitos_topic.select(col('value').cast('string'))\n",
    "topic_string.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Criar a visualização pelo Spark com os dados enviados para o HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAINEL 4 - Síntese de casos, óbitos, incidência e mortalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----------------+-----------------+----------+-----------+\n",
      "|      regiao|estado|Casos_Acumulados|Óbitos_Acumulados|Incidência|Mortalidade|\n",
      "+------------+------+----------------+-----------------+----------+-----------+\n",
      "|      Brasil|  null|        18855015|           526892|    8972.3|      250.7|\n",
      "|Centro-Oeste|    GO|          686433|            19485|    9780.5|      277.6|\n",
      "|Centro-Oeste|    DF|          434708|             9322|   14416.9|      309.2|\n",
      "|Centro-Oeste|    MS|          339323|             8400|   12210.3|      302.3|\n",
      "|Centro-Oeste|    MT|          456155|            12000|   13091.1|      344.4|\n",
      "|    Nordeste|    PI|          299084|             6662|    9137.3|      203.5|\n",
      "|    Nordeste|    MA|          322052|             9190|    4551.9|      129.9|\n",
      "|    Nordeste|    PE|          561505|            17953|    5875.3|      187.9|\n",
      "|    Nordeste|    BA|         1141612|            24428|    7675.7|      164.2|\n",
      "|    Nordeste|    RN|          347248|             6853|    9902.0|      195.4|\n",
      "|    Nordeste|    AL|          220793|             5450|    6615.8|      163.3|\n",
      "|    Nordeste|    CE|          894678|            22791|    9797.1|      249.6|\n",
      "|    Nordeste|    PB|          402175|             8724|   10009.0|      217.1|\n",
      "|    Nordeste|    SE|          266590|             5773|   11597.4|      251.1|\n",
      "|       Norte|    TO|          200243|             3266|   12731.1|      207.6|\n",
      "|       Norte|    AC|           85997|             1760|    9750.9|      199.6|\n",
      "|       Norte|    RR|          113758|             1763|   18779.4|      291.0|\n",
      "|       Norte|    PA|          557708|            15624|    6482.8|      181.6|\n",
      "|       Norte|    AM|          405066|            13349|    9773.4|      322.1|\n",
      "|       Norte|    AP|          118066|             1857|   13960.2|      219.6|\n",
      "|       Norte|    RO|          252024|             6226|   14180.8|      350.3|\n",
      "|     Sudeste|    RJ|          970268|            56192|    5619.9|      325.5|\n",
      "|     Sudeste|    MG|         1836198|            47148|    8674.1|      222.7|\n",
      "|     Sudeste|    SP|         3809222|           130389|    8295.5|      284.0|\n",
      "|     Sudeste|    ES|          523115|            11582|   13017.2|      288.2|\n",
      "|         Sul|    RS|         1235914|            31867|   10863.0|      280.1|\n",
      "|         Sul|    PR|         1308643|            31692|   11445.2|      277.2|\n",
      "|         Sul|    SC|         1066484|            17146|   14885.1|      239.3|\n",
      "+------------+------+----------------+-----------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Número de casos acumulados, óbitos acumulados, incidência e mortalidade - nível regional (06/07/2021)\n",
    "\n",
    "sintese = df.groupBy(['regiao', 'estado'])\\\n",
    "            .agg({'casosAcumulado':'max', 'obitosAcumulado':'max', 'populacaoTCU2019':'max'})\n",
    "\n",
    "sintese = (sintese\n",
    "       .withColumnRenamed('max(populacaoTCU2019)','População')\n",
    "       .withColumnRenamed('max(casosAcumulado)', 'Casos_Acumulados')\n",
    "       .withColumnRenamed('max(obitosAcumulado)','Óbitos_Acumulados'))\n",
    "\n",
    "sintese = (sintese\n",
    "           .withColumn('Incidência', f.round(sintese['Casos_Acumulados']/sintese['População']*100000,1))\n",
    "           .withColumn('Mortalidade', f.round(sintese['Óbitos_Acumulados']/sintese['População']*100000,1)))\n",
    "                             \n",
    "                             \n",
    "sintese.drop('População').sort(col('regiao').asc()).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Salvar a visualização do exercício 6 em um tópico no Elastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch==7.9\n",
      "  Downloading elasticsearch-7.9.0-py2.py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 523 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /opt/anaconda3/lib/python3.6/site-packages (from elasticsearch==7.9) (2019.11.28)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/anaconda3/lib/python3.6/site-packages (from elasticsearch==7.9) (1.26.11)\n",
      "Installing collected packages: elasticsearch\n",
      "Successfully installed elasticsearch-7.9.0\n"
     ]
    }
   ],
   "source": [
    "# Instalação do pacote necessário\n",
    "\n",
    "!pip install elasticsearch==7.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: acryl-datahub 0.8.27.1\n",
      "Uninstalling acryl-datahub-0.8.27.1:\n",
      "  Would remove:\n",
      "    /opt/anaconda3/bin/datahub\n",
      "    /opt/anaconda3/lib/python3.6/site-packages/acryl_datahub-0.8.27.1.dist-info/*\n",
      "    /opt/anaconda3/lib/python3.6/site-packages/datahub/*\n",
      "    /opt/anaconda3/lib/python3.6/site-packages/datahub_provider/*\n",
      "Proceed (y/n)? "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Configurando a conexão com o Elastic\n",
    "es = Elasticsearch('192.168.56.140:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'node1',\n",
       " 'cluster_name': 'my_cluster',\n",
       " 'cluster_uuid': '5PaO_OHESkuiq3X1i8a14w',\n",
       " 'version': {'number': '7.9.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n",
       "  'build_date': '2020-09-23T00:45:33.626720Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a configuração do Elastichsearch\n",
    "\n",
    "es.info(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A visualização do exercício 6 é o terceito painel, com dataframe de nome obitos_br\n",
    "# Transformando o tipo da coluna para float\n",
    "\n",
    "obitos_br = obitos_br.withColumn(\"Letalidade\", col(\"Letalidade\").cast(FloatType()))\\\n",
    "                     .withColumn(\"Mortalidade\", col(\"Mortalidade\").cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o420.save.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 23.0 failed 1 times, most recent failure: Lost task 2.0 in stage 23.0 (TID 41, localhost, executor driver): org.apache.spark.util.TaskCompletionListenerException: Could not write all entries for bulk operation [1/1]. Error sample (first [5] error messages):\n\torg.elasticsearch.hadoop.rest.EsHadoopRemoteException: cluster_block_exception: index [br_dashboard] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];\n\t{\"index\":{}}\n{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}\n\nBailing out...\n\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)\n\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:137)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:101)\n\tat org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:620)\n\tat org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:108)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.util.TaskCompletionListenerException: Could not write all entries for bulk operation [1/1]. Error sample (first [5] error messages):\n\torg.elasticsearch.hadoop.rest.EsHadoopRemoteException: cluster_block_exception: index [br_dashboard] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];\n\t{\"index\":{}}\n{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}\n\nBailing out...\n\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)\n\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:137)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c0409566fe13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Enviando os dados para o Elastic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobitos_br\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"org.elasticsearch.spark.sql\"\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es.nodes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"192.168.56.140\"\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es.port\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'9200'\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es.resource\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'br_dashboard/sample'\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es.nodes.wan.only\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o420.save.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 23.0 failed 1 times, most recent failure: Lost task 2.0 in stage 23.0 (TID 41, localhost, executor driver): org.apache.spark.util.TaskCompletionListenerException: Could not write all entries for bulk operation [1/1]. Error sample (first [5] error messages):\n\torg.elasticsearch.hadoop.rest.EsHadoopRemoteException: cluster_block_exception: index [br_dashboard] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];\n\t{\"index\":{}}\n{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}\n\nBailing out...\n\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)\n\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:137)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:101)\n\tat org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:620)\n\tat org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:108)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.util.TaskCompletionListenerException: Could not write all entries for bulk operation [1/1]. Error sample (first [5] error messages):\n\torg.elasticsearch.hadoop.rest.EsHadoopRemoteException: cluster_block_exception: index [br_dashboard] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];\n\t{\"index\":{}}\n{\"Região\":\"Brasil\",\"Óbitos_Acumulados\":526892,\"Óbitos_Novos\":1780,\"Letalidade\":2.8,\"Mortalidade\":250.7}\n\nBailing out...\n\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)\n\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:137)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Enviando os dados para o Elastic\n",
    "\n",
    "obitos_br.write.format(\"org.elasticsearch.spark.sql\") \\\n",
    "                .option(\"es.nodes\", \"192.168.56.140\") \\\n",
    "                .option(\"es.port\", '9200')\\\n",
    "                .option(\"es.resource\", 'br_dashboard/sample') \\\n",
    "                .option(\"es.nodes.wan.only\", \"true\") \\\n",
    "                .mode('overwrite')\\\n",
    "                .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 0, 'relation': 'eq'},\n",
       "  'max_score': None,\n",
       "  'hits': []}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os dados no Elastic\n",
    "\n",
    "es.search(index=\"br_dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - Criar um dashboard no Elastic para visualização dos novos dados enviados.\n",
    "O dashboard Não possui muitas informaçoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
